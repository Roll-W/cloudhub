# cloudhub-meta-server

元数据服务器的部分工作流程说明。

## 元数据服务器管理

元数据服务器设计中支持设置备份节点以保证系统可用性。
当主节点宕机时，备份节点需要能够接管主节点的工作。

所有的`meta-server`分为三种角色：`leader`、`follower`、`candidate`。

- leader：主`meta-server`节点，负责向外提供服务。`leader`产生于节点选举或预先配置。在一个活动的`meta-server`
  集群中最多只存在一个 `leader` 节点。
- follower：备份 `meta-server` 节点。在一个活动的`meta-server`集群中除
  leader 外的其余节点均为`follower`。
- candidate：选举候选节点，只存在于节点`leader`选举过程中。表示一个合法的`leader`候选节点。

每个meta-server节点都需要预先配置一个`leader`服务器（除`leader`节点外）。
`meta-server` 启动后检查集群节点中是否存在链式指向或循环指向，
若集群已经选举出`leader`则不再进行。
当检测到 meta-server 中存在链式指向或循环指向时，则发起选举过程。

`follower` 只定期接收来自 `leader` 的心跳和同步信息，而不接收其他请求。
当经过一定周期未接收到`leader`的心跳信息时则视为`leader`宕机，
`follower`需要转换为`candidate`节点并发起选举过程。

心跳数据中包含以下信息：

- 服务器地址
- RPC请求端口
- 服务器ID（UUID）

以及可选的信息：

- 发送心跳时的时间戳
- 集群中全体meta-server节点信息（包含在首次发送和集群变化时）
- 集群中全体file-server节点信息（包含在首次发送和集群变化时）

### 选举过程

节点选举过程发生在系统初始化中出现链式指向或循环指向及 leader 宕机时。
节点选举算法基于 RAFT 共识算法修改而来，具体算法如下：

#### 选举过程

每个节点在选举初始时的角色都为`follower`，并都存在一个随机延迟的定时器，每接收到来自`leader`的信息后就将定时器重置。
在定时器到时后，视作`leader`不存在并开始选举过程。

此时节点转换为`candidate`并向其他所有节点发起投票请求，其他节点需要判断是否投票。

当此节点获得半数以上的投票即可成为新的`leader`，并向其他节点通知新的`leader`信息，
其余节点转换为`follower`并与`leader`维持心跳信息。

如果`candidate`在一定时间内未获得足够投票，视为选举失败并开始新一轮的选举，直到出现一个`leader`。

#### 任期

从`leader`被选出到下一次选举开始前称作一个任期。每个节点都维护一个任期编号，
每次选举开始时任期编号加一。

每个节点接收到比自己更大的任期编号时，
更新自己的任期编号并转换为`follower`，而收到更小的编号则忽略或拒绝请求。

#### 投票限制

在投票过程中，所有节点遵循“先来先得”的原则，在一个任期内只可投票给一个节点且得到超过半数的投票才可成为 `leader`，
从而保证一个任期中只会有一个 `leader` 产生。

投票请求中除包含`candidate`的任期编号和服务器信息外，还需包含最新数据的序号。

接收者只投票给拥有相同或更大（即更新的）数据序号的`candidate`。

这保证了只有拥有最新数据的节点才可成为`leader`。

当节点完成投票后则不再发起投票直到下一次选举开始。

#### 选举完成

选举完成后，`meta-server`集群内所有节点向所有已连接的`file-server`发送新的`leader`地址，
以切换到新的`leader`并维持心跳信息。

为保证集群在选举过程中的可用性，首个发起选举的节点将成为临时`leader`，维持与文件服务器间的通信，
但此时不会与其他`meta-server`节点进行数据同步，直到新的`leader`选举出来后，
再由新`leader`获取并同步选举过程中在此节点上产生的所有数据。

## 文件服务器管理

文件服务器管理需要确认文件服务器的活动状态，通过文件服务器向元数据服务器发送心跳实现。

当元数据服务器在经过2到3个心跳周期未接受到心跳时，视为文件服务器宕机，
将此服务器移除出活动服务器列表。

元数据服务器还需要知晓文件服务器的存储情况（通过元数据服务器响应告知是否需要）。

为了使网络延迟纳入可控范围，文件服务器同时还可附上时间戳，
以便元数据服务器计算延迟，适当延长心跳周期。

心跳数据中包含以下信息：

- 服务器地址
- RPC请求端口
- 服务器ID（UUID）

以及可选的信息（通过元数据服务器的响应告知是否需要）：

- 发送心跳时的时间戳
- 文件服务器的状态值
- 文件服务器的具体状态
- 文件服务器的错误信息
    - 需要包含受到影响或损坏的文件ID。

## 文件服务器分配

文件服务器分配包括两方面：

- 一是上传文件时的分配。优先存储到剩余空间较大的文件服务器中，同时需要保证文件不重复存储。
- 二是获取文件时的分配。将客户端的文件请求分散到不同的文件服务器中，利于下载获取时并行传输，提高下载速度。

下面分别介绍两个分配的实现方式。

### 上传文件

通过一致性哈希算法，在根据文件服务器剩余存储空间加权的基础上，
根据请求的文件哈希值分配到文件服务器上，具体分配方法请见[文件主副本位置](#文件主副本位置)。
> 未实现部分：
>
> 将文件分块后分别发送到不同服务器上，减轻单个服务器存储压力。

详细上传过程：

1. meta-server首先检查存储信息，如果数据库中存在文件信息
    - 存在信息时，向`master`发送请求，`master`验证本地存在文件后返回文件存在响应。
    - 若`master`宕机，则向`replica`服务器发起请求。`replica`存在文件返回文件存在响应，
      不存在时对所有`replica`依次继续发起请求。
    - 若所有replica均不存在文件，按照上传新文件的流程发起请求。
    - 假设所有服务器全部宕机，则按照上传新文件的流程发送请求
2. meta-server依照文件哈希值分配`master`服务器及`replica`服务器。
3. 向`master`服务器发送确认信息，包含`replica`服务器信息。
4. 传输文件数据
5. 发送过后，`master`检查本地文件信息，发回确认。若检查错误则重新传输文件数据。
6. 校验成功后，meta-server关闭响应。`master`开始发起副本请求。

### 获取文件

读取出文件的主机地址，若配置了文件副本，则一同返回副本服务器地址。

获取方式：

- 在获取到所有地址后，依据存储的文件长度信息，对所有服务器发起分块下载请求。
    - 当前允许按照块（Block）下标范围及字节范围请求
- 对当前IO负载最小的服务器发起完整文件的获取请求。

## 文件主副本位置

分配文件副本服务器位置的方式与上传文件时分配服务器的方式基本相同。
分配副本服务器采用一主二从一共三副本的方式进行分配。主副本即为上传时分配的服务器。

服务器分配使用一致性哈希算法，依照给定的服务器权重创建虚拟哈希节点。
将所有节点映射到一个首位相连的哈希环上。

通过此种方式分配，能够尽量使哈希值相近的集中在几台服务器中，提高块利用率。

## 管理文件同步

文件同步的发起可以有多种方式：

- 文件服务器请求发起（发生在文件服务器块变动时）
- 元数据服务器发起（一般发生在文件服务器数据损坏时）
- 手动发起

## 管理文件状态

元数据服务器还可对文件状态进行追溯管理。

文件在存储过程中可能会经历以下状态或过程：

|    状态     |               说明                |
|:---------:|:-------------------------------:|
| TEMPORARY |       处于元文件服务器的暂存区，文件不可用。       |
|  STORING  |      处于文件服务器存储的过程中,文件不可用。       |
|  SYNCING  | 处于文件服务器存储中，副本同步状态，文件当前可用，副本不可用。 |
| AVAILABLE |           文件和副本现在都可用。           |
|   LOST    |           文件和副本都丢失了。            |

在上传完成后，服务器保存文件的副本位置用于之后获取时使用。

## 清除副本

> 此功能尚未实现

当主机master确认丢失且不会再恢复时，可以发起清除副本过程。

元数据服务器会尝试向所有有记录的副本服务器发起清除请求，以释放部分磁盘空间。
